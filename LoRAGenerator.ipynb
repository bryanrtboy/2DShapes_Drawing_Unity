{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOuZsDJV8iixbiegG6j+rpq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bryanrtboy/2DShapes_Drawing_Unity/blob/master/LoRAGenerator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Start clean\n",
        "import os, platform\n",
        "os.chdir(\"/content\")\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "print(\"Python:\", platform.python_version())\n",
        "\n",
        "# 1) Remove conflicting wheels\n",
        "!pip -q uninstall -y numpy opencv-python opencv-contrib-python opencv-python-headless >/dev/null 2>&1\n",
        "\n",
        "# 2) Install versions that play nicely together\n",
        "!pip -q install \"numpy==1.26.4\"\n",
        "# This OpenCV build is known-good with NumPy 1.26.x on Colab\n",
        "!pip -q install \"opencv-python-headless==4.8.1.78\"\n",
        "\n",
        "# 3) Re-pin the rest of the stack (same stable set we used)\n",
        "!pip -q uninstall -y diffusers huggingface_hub transformers accelerate bitsandbytes datasets peft >/dev/null 2>&1\n",
        "!pip -q install \"torch==2.3.1\" \"torchvision==0.18.1\" --index-url https://download.pytorch.org/whl/cu121\n",
        "!pip -q install \"huggingface_hub==0.23.2\" \"diffusers==0.25.0\" \"transformers==4.41.1\" \"safetensors==0.4.3\" \"datasets==2.20.0\" ftfy\n",
        "\n",
        "# 4) Verify cv2 + numpy load cleanly\n",
        "import numpy as np, cv2\n",
        "print(\"NumPy:\", np.__version__, \"| OpenCV:\", cv2.__version__)\n",
        "\n",
        "# 5) Ensure sd-scripts present\n",
        "if not os.path.exists(\"/content/sd-scripts/train_network.py\"):\n",
        "    !git clone https://github.com/kohya-ss/sd-scripts.git /content/sd-scripts\n",
        "%cd /content/sd-scripts\n",
        "!pip -q install -r requirements.txt\n",
        "\n",
        "# 6) Warm tokenizer (avoid first-time stall)\n",
        "from transformers import CLIPTokenizerFast\n",
        "_ = CLIPTokenizerFast.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
        "print(\"Tokenizer ready.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7R7BFVnwYkXg",
        "outputId": "181072ae-1da5-431a-cade-22977b7a3578"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Python: 3.11.13\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albucore 0.0.24 requires opencv-python-headless>=4.9.0.80, which is not installed.\n",
            "dopamine-rl 4.1.2 requires opencv-python>=3.4.8.29, which is not installed.\n",
            "albumentations 2.0.8 requires opencv-python-headless>=4.9.0.80, which is not installed.\n",
            "pymc 5.25.1 requires rich>=13.7.1, but you have rich 13.7.0 which is incompatible.\n",
            "gradio 5.41.0 requires huggingface-hub<1.0,>=0.33.5, but you have huggingface-hub 0.24.5 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albucore 0.0.24 requires opencv-python-headless>=4.9.0.80, but you have opencv-python-headless 4.8.1.78 which is incompatible.\n",
            "albumentations 2.0.8 requires opencv-python-headless>=4.9.0.80, but you have opencv-python-headless 4.8.1.78 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gradio 5.41.0 requires huggingface-hub<1.0,>=0.33.5, but you have huggingface-hub 0.23.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mNumPy: 2.0.2 | OpenCV: 4.8.1\n",
            "/content/sd-scripts\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33m  DEPRECATION: Legacy editable install of library==0.0.0 from file:///content/sd-scripts (from -r requirements.txt (line 42)) (setup.py develop) is deprecated. pip 25.3 will enforce this behaviour change. A possible replacement is to add a pyproject.toml or enable --use-pep517, and use setuptools >= 64. If the resulting installation is not behaving as expected, try using --config-settings editable_mode=compat. Please consult the setuptools documentation for more information. Discussion can be found at https://github.com/pypa/pip/issues/11457\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gradio 5.41.0 requires huggingface-hub<1.0,>=0.33.5, but you have huggingface-hub 0.24.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mTokenizer ready.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, json, pathlib, subprocess\n",
        "os.chdir(\"/content\")\n",
        "\n",
        "BASE   = \"/content/drive/MyDrive/lora_base_models/v1-5-pruned-emaonly.safetensors\"\n",
        "TRAIN  = \"/content/drive/MyDrive/lora_data/bryan_paintings\"      # images + .txt\n",
        "OUTTMP = \"/content/out\"                                          # local (fast)\n",
        "OUTDRV = \"/content/drive/MyDrive/lora_outputs/bryan_painterly\"   # Drive\n",
        "NAME   = \"BryanL_Painterly_LoRA\"\n",
        "\n",
        "print(\"Base exists:\", os.path.isfile(BASE))\n",
        "pathlib.Path(OUTTMP).mkdir(parents=True, exist_ok=True)\n",
        "pathlib.Path(OUTDRV).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Dataset config (512 for VRAM safety; you can bump to 640/768 after this works)\n",
        "cfg = {\n",
        "  \"datasets\": [{\n",
        "    \"resolution\": 512,\n",
        "    \"batch_size\": 1,\n",
        "    \"enable_bucket\": True,\n",
        "    \"min_bucket_reso\": 256,\n",
        "    \"max_bucket_reso\": 1024,\n",
        "    \"subsets\": [{\n",
        "      \"image_dir\": TRAIN,\n",
        "      \"caption_extension\": \".txt\",\n",
        "      \"num_repeats\": 1\n",
        "    }]\n",
        "  }]\n",
        "}\n",
        "with open(\"/content/ds.json\",\"w\") as f: json.dump(cfg, f, indent=2)\n",
        "print(open(\"/content/ds.json\").read())\n",
        "\n",
        "# ---- 1-step MUST-WRITE smoke test (bf16, no cache_latents) ----\n",
        "cmd1 = \"\"\"\n",
        "python -u /content/sd-scripts/train_network.py \\\n",
        "  --pretrained_model_name_or_path \"/content/drive/MyDrive/lora_base_models/v1-5-pruned-emaonly.safetensors\" \\\n",
        "  --dataset_config \"/content/ds.json\" \\\n",
        "  --output_dir \"/content/out\" \\\n",
        "  --output_name \"BryanL_Painterly_LoRA\" \\\n",
        "  --network_module networks.lora \\\n",
        "  --network_dim 16 --network_alpha 16 \\\n",
        "  --optimizer_type adamw \\\n",
        "  --learning_rate 1e-4 --text_encoder_lr 5e-5 \\\n",
        "  --max_train_steps 1 \\\n",
        "  --save_every_n_steps 1 \\\n",
        "  --mixed_precision bf16 \\\n",
        "  --shuffle_caption \\\n",
        "  --gradient_checkpointing \\\n",
        "  --max_data_loader_n_workers 0 \\\n",
        "  --save_model_as safetensors 2>&1 | tee /content/train_one_step.log\n",
        "\"\"\"\n",
        "print(cmd1)\n",
        "subprocess.run(cmd1, shell=True, check=False)\n",
        "\n",
        "print(\"\\nLocal out listing after 1-step:\")\n",
        "!ls -lah /content/out || true\n",
        "print(\"\\nLast 40 lines of log:\")\n",
        "!tail -n 40 /content/train_one_step.log || true\n",
        "\n",
        "# ---- Full run (safe) ----\n",
        "cmd2 = \"\"\"\n",
        "python -u /content/sd-scripts/train_network.py \\\n",
        "  --pretrained_model_name_or_path \"/content/drive/MyDrive/lora_base_models/v1-5-pruned-emaonly.safetensors\" \\\n",
        "  --dataset_config \"/content/ds.json\" \\\n",
        "  --output_dir \"/content/out\" \\\n",
        "  --output_name \"BryanL_Painterly_LoRA\" \\\n",
        "  --network_module networks.lora \\\n",
        "  --network_dim 16 --network_alpha 16 \\\n",
        "  --optimizer_type adamw \\\n",
        "  --learning_rate 1e-4 --text_encoder_lr 5e-5 \\\n",
        "  --max_train_steps 4000 \\\n",
        "  --save_every_n_steps 500 \\\n",
        "  --mixed_precision bf16 \\\n",
        "  --cache_latents \\\n",
        "  --shuffle_caption \\\n",
        "  --gradient_checkpointing \\\n",
        "  --max_data_loader_n_workers 0 \\\n",
        "  --save_model_as safetensors 2>&1 | tee /content/train_full.log\n",
        "\"\"\"\n",
        "print(\"\\nStarting FULL run…\")\n",
        "subprocess.run(cmd2, shell=True, check=False)\n",
        "\n",
        "print(\"\\nLocal out listing after full run:\")\n",
        "!ls -lah /content/out || true\n",
        "\n",
        "print(\"\\nCopying to Drive…\")\n",
        "!cp -v /content/out/*.safetensors \"/content/drive/MyDrive/lora_outputs/bryan_painterly/\" 2>/dev/null || true\n",
        "!ls -lah \"/content/drive/MyDrive/lora_outputs/bryan_painterly\" || true\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvXKC7lGZnjb",
        "outputId": "4d8b8a49-4682-4ec0-9be0-c8c87ce652a1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Base exists: True\n",
            "{\n",
            "  \"datasets\": [\n",
            "    {\n",
            "      \"resolution\": 512,\n",
            "      \"batch_size\": 1,\n",
            "      \"enable_bucket\": true,\n",
            "      \"min_bucket_reso\": 256,\n",
            "      \"max_bucket_reso\": 1024,\n",
            "      \"subsets\": [\n",
            "        {\n",
            "          \"image_dir\": \"/content/drive/MyDrive/lora_data/bryan_paintings\",\n",
            "          \"caption_extension\": \".txt\",\n",
            "          \"num_repeats\": 1\n",
            "        }\n",
            "      ]\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "\n",
            "python -u /content/sd-scripts/train_network.py   --pretrained_model_name_or_path \"/content/drive/MyDrive/lora_base_models/v1-5-pruned-emaonly.safetensors\"   --dataset_config \"/content/ds.json\"   --output_dir \"/content/out\"   --output_name \"BryanL_Painterly_LoRA\"   --network_module networks.lora   --network_dim 16 --network_alpha 16   --optimizer_type adamw   --learning_rate 1e-4 --text_encoder_lr 5e-5   --max_train_steps 1   --save_every_n_steps 1   --mixed_precision bf16   --shuffle_caption   --gradient_checkpointing   --max_data_loader_n_workers 0   --save_model_as safetensors 2>&1 | tee /content/train_one_step.log\n",
            "\n",
            "\n",
            "Local out listing after 1-step:\n",
            "total 73M\n",
            "drwxr-xr-x 2 root root 4.0K Aug 13 03:14 .\n",
            "drwxr-xr-x 1 root root 4.0K Aug 13 03:10 ..\n",
            "-rw-r--r-- 1 root root  37M Aug 13 03:14 BryanL_Painterly_LoRA.safetensors\n",
            "-rw-r--r-- 1 root root  37M Aug 13 03:14 BryanL_Painterly_LoRA-step00000001.safetensors\n",
            "\n",
            "Last 40 lines of log:\n",
            "                             modules                                            \n",
            "                    INFO     enable LoRA for U-Net: 192 modules     lora.py:1089\n",
            "                    INFO     CrossAttnDownBlock2D False -> original_unet.py:1521\n",
            "                             True                                               \n",
            "                    INFO     CrossAttnDownBlock2D False -> original_unet.py:1521\n",
            "                             True                                               \n",
            "                    INFO     CrossAttnDownBlock2D False -> original_unet.py:1521\n",
            "                             True                                               \n",
            "                    INFO     DownBlock2D False -> True     original_unet.py:1521\n",
            "                    INFO     UNetMidBlock2DCrossAttn False original_unet.py:1521\n",
            "                             -> True                                            \n",
            "                    INFO     UpBlock2D False -> True       original_unet.py:1521\n",
            "                    INFO     CrossAttnUpBlock2D False ->   original_unet.py:1521\n",
            "                             True                                               \n",
            "                    INFO     CrossAttnUpBlock2D False ->   original_unet.py:1521\n",
            "                             True                                               \n",
            "                    INFO     CrossAttnUpBlock2D False ->   original_unet.py:1521\n",
            "                             True                                               \n",
            "prepare optimizer, data loader etc.\n",
            "                    INFO     use AdamW optimizer | {}         train_util.py:4368\n",
            "running training / 学習開始\n",
            "  num train images * repeats / 学習画像の数×繰り返し回数: 21\n",
            "  num reg images / 正則化画像の数: 0\n",
            "  num batches per epoch / 1epochのバッチ数: 21\n",
            "  num epochs / epoch数: 1\n",
            "  batch size per device / バッチサイズ: 1\n",
            "  gradient accumulation steps / 勾配を合計するステップ数 = 1\n",
            "  total optimization steps / 学習ステップ数: 1\n",
            "steps:   0%|          | 0/1 [00:00<?, ?it/s]\n",
            "epoch 1/1\n",
            "2025-08-13 03:14:43 INFO     epoch is incremented.             train_util.py:693\n",
            "                             current_epoch: 0, epoch: 1                         \n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "steps: 100%|██████████| 1/1 [00:01<00:00,  1.59s/it]\n",
            "saving checkpoint: /content/out/BryanL_Painterly_LoRA-step00000001.safetensors\n",
            "steps: 100%|██████████| 1/1 [00:01<00:00,  1.92s/it, avr_loss=0.00344]\n",
            "saving checkpoint: /content/out/BryanL_Painterly_LoRA.safetensors\n",
            "2025-08-13 03:14:45 INFO     model saved.                  train_network.py:1112\n",
            "steps: 100%|██████████| 1/1 [00:02<00:00,  2.24s/it, avr_loss=0.00344]\n",
            "\n",
            "Starting FULL run…\n",
            "\n",
            "Local out listing after full run:\n",
            "total 362M\n",
            "drwxr-xr-x 2 root root 4.0K Aug 13 03:51 .\n",
            "drwxr-xr-x 1 root root 4.0K Aug 13 03:10 ..\n",
            "-rw-r--r-- 1 root root  37M Aug 13 03:51 BryanL_Painterly_LoRA.safetensors\n",
            "-rw-r--r-- 1 root root  37M Aug 13 03:14 BryanL_Painterly_LoRA-step00000001.safetensors\n",
            "-rw-r--r-- 1 root root  37M Aug 13 03:20 BryanL_Painterly_LoRA-step00000500.safetensors\n",
            "-rw-r--r-- 1 root root  37M Aug 13 03:24 BryanL_Painterly_LoRA-step00001000.safetensors\n",
            "-rw-r--r-- 1 root root  37M Aug 13 03:29 BryanL_Painterly_LoRA-step00001500.safetensors\n",
            "-rw-r--r-- 1 root root  37M Aug 13 03:33 BryanL_Painterly_LoRA-step00002000.safetensors\n",
            "-rw-r--r-- 1 root root  37M Aug 13 03:38 BryanL_Painterly_LoRA-step00002500.safetensors\n",
            "-rw-r--r-- 1 root root  37M Aug 13 03:42 BryanL_Painterly_LoRA-step00003000.safetensors\n",
            "-rw-r--r-- 1 root root  37M Aug 13 03:47 BryanL_Painterly_LoRA-step00003500.safetensors\n",
            "-rw-r--r-- 1 root root  37M Aug 13 03:51 BryanL_Painterly_LoRA-step00004000.safetensors\n",
            "\n",
            "Copying to Drive…\n",
            "'/content/out/BryanL_Painterly_LoRA.safetensors' -> '/content/drive/MyDrive/lora_outputs/bryan_painterly/BryanL_Painterly_LoRA.safetensors'\n",
            "'/content/out/BryanL_Painterly_LoRA-step00000001.safetensors' -> '/content/drive/MyDrive/lora_outputs/bryan_painterly/BryanL_Painterly_LoRA-step00000001.safetensors'\n",
            "'/content/out/BryanL_Painterly_LoRA-step00000500.safetensors' -> '/content/drive/MyDrive/lora_outputs/bryan_painterly/BryanL_Painterly_LoRA-step00000500.safetensors'\n",
            "'/content/out/BryanL_Painterly_LoRA-step00001000.safetensors' -> '/content/drive/MyDrive/lora_outputs/bryan_painterly/BryanL_Painterly_LoRA-step00001000.safetensors'\n",
            "'/content/out/BryanL_Painterly_LoRA-step00001500.safetensors' -> '/content/drive/MyDrive/lora_outputs/bryan_painterly/BryanL_Painterly_LoRA-step00001500.safetensors'\n",
            "'/content/out/BryanL_Painterly_LoRA-step00002000.safetensors' -> '/content/drive/MyDrive/lora_outputs/bryan_painterly/BryanL_Painterly_LoRA-step00002000.safetensors'\n",
            "'/content/out/BryanL_Painterly_LoRA-step00002500.safetensors' -> '/content/drive/MyDrive/lora_outputs/bryan_painterly/BryanL_Painterly_LoRA-step00002500.safetensors'\n",
            "'/content/out/BryanL_Painterly_LoRA-step00003000.safetensors' -> '/content/drive/MyDrive/lora_outputs/bryan_painterly/BryanL_Painterly_LoRA-step00003000.safetensors'\n",
            "'/content/out/BryanL_Painterly_LoRA-step00003500.safetensors' -> '/content/drive/MyDrive/lora_outputs/bryan_painterly/BryanL_Painterly_LoRA-step00003500.safetensors'\n",
            "'/content/out/BryanL_Painterly_LoRA-step00004000.safetensors' -> '/content/drive/MyDrive/lora_outputs/bryan_painterly/BryanL_Painterly_LoRA-step00004000.safetensors'\n",
            "total 362M\n",
            "-rw------- 1 root root 37M Aug 13 03:51 BryanL_Painterly_LoRA.safetensors\n",
            "-rw------- 1 root root 37M Aug 13 03:51 BryanL_Painterly_LoRA-step00000001.safetensors\n",
            "-rw------- 1 root root 37M Aug 13 03:51 BryanL_Painterly_LoRA-step00000500.safetensors\n",
            "-rw------- 1 root root 37M Aug 13 03:51 BryanL_Painterly_LoRA-step00001000.safetensors\n",
            "-rw------- 1 root root 37M Aug 13 03:51 BryanL_Painterly_LoRA-step00001500.safetensors\n",
            "-rw------- 1 root root 37M Aug 13 03:51 BryanL_Painterly_LoRA-step00002000.safetensors\n",
            "-rw------- 1 root root 37M Aug 13 03:51 BryanL_Painterly_LoRA-step00002500.safetensors\n",
            "-rw------- 1 root root 37M Aug 13 03:51 BryanL_Painterly_LoRA-step00003000.safetensors\n",
            "-rw------- 1 root root 37M Aug 13 03:51 BryanL_Painterly_LoRA-step00003500.safetensors\n",
            "-rw------- 1 root root 37M Aug 13 03:51 BryanL_Painterly_LoRA-step00004000.safetensors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -v /content/out/*.safetensors \"/content/drive/MyDrive/lora_outputs/bryan_painterly/\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5gW0tjTgJ7L",
        "outputId": "3134b0d5-37ed-4e0e-d86c-1026e096d8f8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'/content/out/BryanL_Painterly_LoRA.safetensors' -> '/content/drive/MyDrive/lora_outputs/bryan_painterly/BryanL_Painterly_LoRA.safetensors'\n",
            "'/content/out/BryanL_Painterly_LoRA-step00000001.safetensors' -> '/content/drive/MyDrive/lora_outputs/bryan_painterly/BryanL_Painterly_LoRA-step00000001.safetensors'\n",
            "'/content/out/BryanL_Painterly_LoRA-step00000500.safetensors' -> '/content/drive/MyDrive/lora_outputs/bryan_painterly/BryanL_Painterly_LoRA-step00000500.safetensors'\n",
            "'/content/out/BryanL_Painterly_LoRA-step00001000.safetensors' -> '/content/drive/MyDrive/lora_outputs/bryan_painterly/BryanL_Painterly_LoRA-step00001000.safetensors'\n",
            "'/content/out/BryanL_Painterly_LoRA-step00001500.safetensors' -> '/content/drive/MyDrive/lora_outputs/bryan_painterly/BryanL_Painterly_LoRA-step00001500.safetensors'\n",
            "'/content/out/BryanL_Painterly_LoRA-step00002000.safetensors' -> '/content/drive/MyDrive/lora_outputs/bryan_painterly/BryanL_Painterly_LoRA-step00002000.safetensors'\n",
            "'/content/out/BryanL_Painterly_LoRA-step00002500.safetensors' -> '/content/drive/MyDrive/lora_outputs/bryan_painterly/BryanL_Painterly_LoRA-step00002500.safetensors'\n",
            "'/content/out/BryanL_Painterly_LoRA-step00003000.safetensors' -> '/content/drive/MyDrive/lora_outputs/bryan_painterly/BryanL_Painterly_LoRA-step00003000.safetensors'\n",
            "'/content/out/BryanL_Painterly_LoRA-step00003500.safetensors' -> '/content/drive/MyDrive/lora_outputs/bryan_painterly/BryanL_Painterly_LoRA-step00003500.safetensors'\n",
            "'/content/out/BryanL_Painterly_LoRA-step00004000.safetensors' -> '/content/drive/MyDrive/lora_outputs/bryan_painterly/BryanL_Painterly_LoRA-step00004000.safetensors'\n"
          ]
        }
      ]
    }
  ]
}